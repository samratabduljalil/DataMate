{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.11.11-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.26 (from langchain)\n",
      "  Using cached langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.6-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.1-cp310-cp310-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp310-cp310-win_amd64.whl.metadata (71 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.26->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.12-cp310-none-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.0)\n",
      "Using cached langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
      "Using cached aiohttp-3.11.11-cp310-cp310-win_amd64.whl (442 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Using cached langsmith-0.2.6-py3-none-any.whl (325 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Using cached pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Using cached SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.12-cp310-none-win_amd64.whl (135 kB)\n",
      "Using cached propcache-0.2.1-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached yarl-1.18.3-cp310-cp310-win_amd64.whl (90 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, greenlet, frozenlist, async-timeout, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, pydantic, jsonpatch, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 async-timeout-4.0.3 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.13 langchain-core-0.3.28 langchain-text-splitters-0.3.4 langsmith-0.2.6 multidict-6.1.0 numpy-1.26.4 orjson-3.10.12 propcache-0.2.1 pydantic-2.10.4 pydantic-core-2.27.2 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model_name: str  # Define model_name as a class attribute\n",
    "    server_url: str = \"http://localhost:11434\"  # Default server URL\n",
    "\n",
    "    def __init__(self, model_name: str, server_url: Optional[str] = None):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        if server_url:\n",
    "            self.server_url = server_url\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: list = None) -> str:\n",
    "        # Make a request to the Ollama server\n",
    "        response = requests.post(\n",
    "            f\"{self.server_url}/api/generate\",\n",
    "            json={\"model\": self.model_name, \"prompt\": prompt},\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result.get(\"response\", \"\")\n",
    "        else:\n",
    "            raise ValueError(f\"Error from Ollama server: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OllamaLLM\nmodel_name\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ollama_llm \u001b[38;5;241m=\u001b[39m \u001b[43mOllamaLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama2-7b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Test with a simple prompt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain quantum mechanics in simple terms.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mOllamaLLM.__init__\u001b[1;34m(self, model_name, server_url)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m, server_url: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m server_url:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localrag3.0\\lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\localrag3.0\\lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OllamaLLM\nmodel_name\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "ollama_llm = OllamaLLM(model_name=\"llama2-7b\")\n",
    "\n",
    "# Test with a simple prompt\n",
    "prompt = \"Explain quantum mechanics in simple terms.\"\n",
    "response = ollama_llm(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samrat Abdul Jalil is a Malaysian professional squash player. He was born on August 20, 1982, in Kuala Lumpur, Malaysia.\n",
      "\n",
      "Abdul Jalil has had a successful career in squash, representing Malaysia at the international level. Some of his notable achievements include:\n",
      "\n",
      "1. Asian Games Medalist: He won a silver medal at the 2006 Asian Games in Doha, Qatar, in the men's individual event.\n",
      "2. Commonwealth Games Participant: Abdul Jalil has represented Malaysia at three Commonwealth Games (2002, 2006, and 2010).\n",
      "3. South East Asian Games Champion: He won multiple titles at the South East Asian Games, a regional multi-sport event.\n",
      "\n",
      "Abdul Jalil is considered one of Malaysia's most successful squash players in recent history.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# Connect to the Ollama server\n",
    "ollama_llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    base_url=\"http://127.0.0.1:12345\"\n",
    ")\n",
    "\n",
    "# Test with a prompt\n",
    "prompt = \"who is samrat abdul jalil\"\n",
    "response = ollama_llm(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (3.11.11)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (0.3.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (0.3.28)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (0.2.6)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.0)\n",
      "Using cached langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
      "Using cached marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.13 marshmallow-3.23.2 mypy-extensions-1.0.0 pydantic-settings-2.7.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nomic\n",
      "  Downloading nomic-3.3.4.tar.gz (49 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting click (from nomic)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonlines (from nomic)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting loguru (from nomic)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting rich (from nomic)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from nomic) (2.32.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from nomic) (1.26.4)\n",
      "Collecting pandas (from nomic)\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pydantic in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from nomic) (2.10.4)\n",
      "Collecting tqdm (from nomic)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow (from nomic)\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pillow (from nomic)\n",
      "  Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyjwt (from nomic)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from click->nomic) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from jsonlines->nomic) (24.3.0)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru->nomic)\n",
      "  Downloading win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pandas->nomic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pandas->nomic) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas->nomic)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pydantic->nomic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pydantic->nomic) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from pydantic->nomic) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests->nomic) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests->nomic) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests->nomic) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from requests->nomic) (2024.12.14)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->nomic)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from rich->nomic) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->nomic)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->nomic) (1.16.0)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Downloading pyarrow-18.1.0-cp310-cp310-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/25.1 MB 3.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.3/25.1 MB 2.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.8/25.1 MB 2.5 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.1/25.1 MB 2.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 2.6/25.1 MB 2.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.9/25.1 MB 2.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.4/25.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.7/25.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.2/25.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.5/25.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 5.0/25.1 MB 2.0 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 5.2/25.1 MB 2.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.5/25.1 MB 2.0 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 6.0/25.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.3/25.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 6.8/25.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.1/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.6/25.1 MB 1.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.9/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.4/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.7/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 8.9/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 9.4/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 9.7/25.1 MB 1.9 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 1.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 10.7/25.1 MB 1.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 11.0/25.1 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 11.5/25.1 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 11.8/25.1 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 12.3/25.1 MB 1.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.6/25.1 MB 1.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 12.8/25.1 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 13.4/25.1 MB 1.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 13.6/25.1 MB 1.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 14.2/25.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 14.4/25.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 14.9/25.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 15.2/25.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 15.7/25.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 16.0/25.1 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.5/25.1 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 16.8/25.1 MB 1.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 17.3/25.1 MB 1.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 17.6/25.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 18.1/25.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 18.4/25.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 18.9/25.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 19.1/25.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 19.7/25.1 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.9/25.1 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.2/25.1 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.7/25.1 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 21.0/25.1 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 21.5/25.1 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.0/25.1 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/25.1 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 23.1/25.1 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 23.6/25.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.1/25.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.6/25.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: nomic\n",
      "  Building wheel for nomic (pyproject.toml): started\n",
      "  Building wheel for nomic (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for nomic: filename=nomic-3.3.4-py3-none-any.whl size=49635 sha256=f169ff72289a2fbab58dc823da311eee0ab2806c6a8ed974dfc9900fcba3a2c5\n",
      "  Stored in directory: c:\\users\\samra\\appdata\\local\\pip\\cache\\wheels\\c8\\1d\\bb\\b2f4390b876d28324d00cfbddc4fda198c1c448a27d972b8e4\n",
      "Successfully built nomic\n",
      "Installing collected packages: win32-setctime, tzdata, tqdm, pyjwt, pyarrow, pillow, mdurl, jsonlines, click, pandas, markdown-it-py, loguru, rich, nomic\n",
      "Successfully installed click-8.1.8 jsonlines-4.0.0 loguru-0.7.3 markdown-it-py-3.0.0 mdurl-0.1.2 nomic-3.3.4 pandas-2.2.3 pillow-11.0.0 pyarrow-18.1.0 pyjwt-2.10.1 rich-13.9.4 tqdm-4.67.1 tzdata-2024.2 win32-setctime-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nomic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nomic.atlas' has no attribute 'EmbeddingCollection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is quantum mechanics?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe theory of relativity is fundamental to physics.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine learning is a subset of AI.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m ]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Generate Nomic embeddings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m embedding_collection \u001b[38;5;241m=\u001b[39m \u001b[43msetup_nomic_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Step 2: Store embeddings in Chroma\u001b[39;00m\n\u001b[0;32m     27\u001b[0m documents \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36msetup_nomic_embeddings\u001b[1;34m(texts, embedding_collection_name)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_nomic_embeddings\u001b[39m(texts, embedding_collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnomic_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate embeddings locally using Nomic and store them in an embedding collection.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     collection \u001b[38;5;241m=\u001b[39m \u001b[43matlas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCollection\u001b[49m(name\u001b[38;5;241m=\u001b[39membedding_collection_name)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m     12\u001b[0m         collection\u001b[38;5;241m.\u001b[39madd_entry(text)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nomic.atlas' has no attribute 'EmbeddingCollection'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nomic import atlas\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Step 1: Set up Nomic Atlas Embedding Collection\n",
    "def setup_nomic_embeddings(texts, embedding_collection_name=\"nomic_embeddings\"):\n",
    "    \"\"\"Generate embeddings locally using Nomic and store them in an embedding collection.\"\"\"\n",
    "    collection = atlas.EmbeddingCollection(name=embedding_collection_name)\n",
    "    for text in texts:\n",
    "        collection.add_entry(text)\n",
    "    collection.wait_for_completion()  # Wait until the embeddings are computed\n",
    "    return collection\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"What is quantum mechanics?\",\n",
    "    \"The theory of relativity is fundamental to physics.\",\n",
    "    \"Machine learning is a subset of AI.\"\n",
    "]\n",
    "\n",
    "# Generate Nomic embeddings\n",
    "embedding_collection = setup_nomic_embeddings(texts)\n",
    "\n",
    "# Step 2: Store embeddings in Chroma\n",
    "documents = [Document(page_content=text) for text in texts]\n",
    "\n",
    "# Assuming you have embeddings locally via LangChain-compatible Embeddings class\n",
    "class NomicEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        return embedding_collection.get_embeddings(texts)\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return embedding_collection.get_embedding(text)\n",
    "\n",
    "# Initialize Nomic embeddings\n",
    "nomic_embeddings = NomicEmbeddings()\n",
    "\n",
    "# Create a Chroma vector store\n",
    "vector_store = Chroma.from_documents(documents, nomic_embeddings)\n",
    "\n",
    "# Step 3: Query the Vector Store\n",
    "query = \"Explain the basics of physics.\"\n",
    "similar_docs = vector_store.similarity_search(query)\n",
    "\n",
    "# Print results\n",
    "for i, doc in enumerate(similar_docs, 1):\n",
    "    print(f\"Document {i}: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'nomic.atlas' has no attribute 'EmbeddingCollection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Display the embeddings\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEmbeddings Generated:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(texts, embedding_collection_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mGenerates embeddings for a list of texts using Nomic and returns the collection.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a new embedding collection\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43matlas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCollection\u001b[49m(name\u001b[38;5;241m=\u001b[39membedding_collection_name)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Add texts to the collection for embedding\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nomic.atlas' has no attribute 'EmbeddingCollection'"
     ]
    }
   ],
   "source": [
    "from nomic import atlas\n",
    "\n",
    "# Initialize an Embedding Collection\n",
    "def generate_embeddings(texts, embedding_collection_name=\"test_embeddings\"):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of texts using Nomic and returns the collection.\n",
    "    \"\"\"\n",
    "    # Create a new embedding collection\n",
    "    collection = atlas.EmbeddingCollection(name=embedding_collection_name)\n",
    "    \n",
    "    # Add texts to the collection for embedding\n",
    "    for text in texts:\n",
    "        collection.add_entry(text)\n",
    "    \n",
    "    # Wait until the embeddings are computed\n",
    "    collection.wait_for_completion()\n",
    "    \n",
    "    return collection\n",
    "\n",
    "# Sample texts to embed\n",
    "texts = [\n",
    "    \"Artificial intelligence is transforming industries.\",\n",
    "    \"Quantum mechanics is the study of very small particles.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"The universe is vast and full of mysteries.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings...\")\n",
    "collection = generate_embeddings(texts)\n",
    "\n",
    "# Display the embeddings\n",
    "print(\"\\nEmbeddings Generated:\")\n",
    "for i, text in enumerate(texts):\n",
    "    embedding = collection.get_embedding(text)  # Retrieve embedding for the text\n",
    "    print(f\"Text {i + 1}: {text}\")\n",
    "    print(f\"Embedding {i + 1}: {embedding[:5]}... (truncated for display)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AtlasProject' from 'nomic' (C:\\Users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages\\nomic\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnomic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AtlasProject\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize an Atlas project\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_embeddings\u001b[39m(texts, project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Embedding Project\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AtlasProject' from 'nomic' (C:\\Users\\samra\\anaconda3\\envs\\localrag3.0\\lib\\site-packages\\nomic\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from nomic import AtlasProject\n",
    "\n",
    "# Initialize an Atlas project\n",
    "def generate_embeddings(texts, project_name=\"Test Embedding Project\"):\n",
    "    \"\"\"\n",
    "    Generates embeddings for a list of texts using Nomic and uploads them to an Atlas project.\n",
    "    \"\"\"\n",
    "    # Create or open an Atlas project\n",
    "    project = AtlasProject(name=project_name)\n",
    "\n",
    "    # Add data to the project with embeddings\n",
    "    data = [{'text': text} for text in texts]\n",
    "    project.add_text(data=data, name=\"Sample Text Embeddings\")\n",
    "\n",
    "    # Optionally, visualize the project\n",
    "    print(f\"View your project here: {project.url}\")\n",
    "    return project\n",
    "\n",
    "# Sample texts to embed\n",
    "texts = [\n",
    "    \"Artificial intelligence is transforming industries.\",\n",
    "    \"Quantum mechanics is the study of very small particles.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"The universe is vast and full of mysteries.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings and upload to Atlas\n",
    "print(\"Generating embeddings...\")\n",
    "project = generate_embeddings(texts)\n",
    "\n",
    "# Output the project URL\n",
    "print(\"\\nEmbeddings uploaded successfully!\")\n",
    "print(f\"Project URL: {project.url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
